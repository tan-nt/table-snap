# -*- coding: utf-8 -*-
"""TSR_YOLOv8_experiment_version_5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pdTCJAwi1-C6B42IqVSJdz9bQ3vn8D2E

# YOLO V8 FOR Table Structure Recognition
"""

!export LC_ALL=C.UTF-8
!export LANG=C.UTF-8

!apt-get install -y locales
!locale-gen en_US.UTF-8
!update-locale LC_ALL=en_US.UTF-8 LANG=en_US.UTF-8

import locale
import os

os.environ["LC_ALL"] = "C.UTF-8"
os.environ["LANG"] = "C.UTF-8"
locale.setlocale(locale.LC_ALL, "C.UTF-8")

import locale
print(locale.getpreferredencoding())

fintabnet_original_dataset_dir = 'FinTabNetOriginalDataset'
fintabnet_yolo_format_dataset_dir = 'FinTabNetYoloFormatDataset'

!mkdir -p $fintabnet_yolo_format_dataset_dir
!mkdir -p $fintabnet_yolo_format_dataset_dir/images/train
!mkdir -p $fintabnet_yolo_format_dataset_dir/images/val
!mkdir -p $fintabnet_yolo_format_dataset_dir/images/test
!mkdir -p $fintabnet_yolo_format_dataset_dir/labels/train
!mkdir -p $fintabnet_yolo_format_dataset_dir/labels/val
!mkdir -p $fintabnet_yolo_format_dataset_dir/labels/test

from google.colab import drive
drive.mount('/content/drive')

!cp -r "/content/drive/MyDrive/pubtabnet/demo" /content/$fintabnet_original_dataset_dir

!pip install xmltodict
!pip install ultralytics
!pip install jsonlines
!pip install apted
!pip install Distance
# !pip install pytesseract

import os
import shutil
from tqdm import tqdm
import multiprocessing
from joblib import Parallel, delayed
import jsonlines

max_processes = multiprocessing.cpu_count()
print('max_processes:', max_processes)

def build_table_from_html_and_cell(
    structure, content
):
    """Build table from html and cell token list"""
    assert structure is not None
    html_code = list()

    # deal with empty table
    if content is None:
        content = ["placeholder"] * len(structure)

    for tag in structure:
        if tag in ("<td>[]</td>", ">[]</td>"):
            if len(content) == 0:
                continue
            cell = content.pop(0)
            html_code.append(tag.replace("[]", cell))
        else:
            html_code.append(tag)

    return html_code

CELL_SPECIAL = ["<b>", "</b>", "<i>", "</i>", "<sup>", "</sup>", "<sub>", "</sub>"]

# Load groundtruth annotation
annotation_path = f"{fintabnet_original_dataset_dir}/annotation.jsonl"
with jsonlines.open(annotation_path) as f:
    for obj in f:
        # if obj["filename"] == image_name:
        if obj["filename"] == "PMC1064888_001_02.png":
            anno_html_raw = obj["html"]["structure"]["tokens"]
            anno_cell_raw = ["".join(cell["tokens"]) for cell in obj["html"]["cells"] if cell["tokens"]]
            break

anno_html = []
idx = 0
while idx < len(anno_html_raw):
    if "[" in anno_html_raw[idx]:
        assert idx + 1 < len(anno_html_raw)
        assert anno_html_raw[idx + 1] == "]</td>"
        anno_html.append(anno_html_raw[idx] + "]</td>")
        idx = idx + 2
    else:
        anno_html.append(anno_html_raw[idx])
        idx = idx + 1

anno_cell = []
for txt in anno_cell_raw:
    for black in CELL_SPECIAL:
        txt = txt.replace(black, "")
    anno_cell.append(txt)

anno_code = "".join(build_table_from_html_and_cell(anno_html, anno_cell))
print('anno_code=', anno_code)

import os
import json
from PIL import Image

# Define class mapping for table elements, including spanning cells
class_names_map = {
    # 'table': 0,
    # 'table column': 2,
    # 'table row': 3,
    # 'table projected row header': 5,
    'table cell header': 0,
    'table grid cell': 1,
    # 'table spanning cell': 2, # we use post-processing logic to handle it
}

# Helper function to determine the class of each cell based on structure tokens and cell index
def infer_class_from_structure(structure_tokens, cell_index):
    # anno_code= <thead><tr><td></td><td colspan="7"></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr></thead><tbody><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr></tbody>
    in_thead = False  # Flag to track header section
    in_tbody = False  # Flag to track body section
    current_cell = 1  # Track index within cells

    for token in structure_tokens:
        # Update section flags based on tags
        if token == "<thead>":
            in_thead = True
        elif token == "</thead>":
            in_thead = False
        elif token == "<tbody>":
            in_tbody = True
        elif token == "</tbody>":
            in_tbody = False

        # Immediately classify as spanning cell if 'colspan' or 'rowspan' is present
        if 'colspan' in token or 'rowspan' in token:
            current_cell += 1
            if current_cell == cell_index:
                # print('cell_index=', cell_index, ', current_cell=', current_cell, ', token=', token, ', in_thead=', in_thead, ", in_tbody=", in_tbody)
                # return class_names_map['table spanning cell']
                return class_names_map['table grid cell']

        # End of a cell and classification
        elif token == "</td>":
            if current_cell == cell_index:
                # print('cell_index=', cell_index, ', current_cell=', current_cell, ', token=', token, ', in_thead=', in_thead, ", in_tbody=", in_tbody)
                # Determine class based on current section
                if in_thead:
                    return class_names_map['table cell header']
                elif in_tbody:
                    return class_names_map['table grid cell']
            # Only increment current_cell after completing <td>...</td> processing
            current_cell += 1
            inside_cell = False  # Reset flag after finishing a cell

    # Default class as table if no specific classification is found
    return class_names_map['table grid cell']

# Function to convert PubTabNet JSON annotation to YOLO format
def pubtabnet_to_yolo_single(data, yolo_base_dir, image_base_dir):
    image_path = os.path.join(image_base_dir, data['filename'])
    with Image.open(image_path) as img:
        fix_width, fix_height = img.size

    output_filename = f"{os.path.splitext(data['filename'])[0]}.txt"
    output_path = os.path.join(yolo_base_dir, output_filename)
    os.makedirs(os.path.dirname(output_path), exist_ok=True)

    # Get structure tokens for context
    # print("data structure=", data.get("structure"))
    structure_tokens = data.get("html", {}).get('structure', {}).get('tokens', [])
    # print("structure_tokens=",structure_tokens)

    # Collect bounding box data
    yolo_data = []
    for i, cell in enumerate(data['html']['cells']):
        if 'bbox' in cell:
            x0, y0, x1, y1 = cell['bbox']
            # print("cell_index=", i)
            # Determine class_id based on structure tokens and attributes like colspan/rowspan
            class_id = infer_class_from_structure(structure_tokens, i)
            # print("class_id", class_id)
            # Convert bbox to YOLO format
            w = x1 - x0
            h = y1 - y0
            center_x = (x0 + x1) / 2
            center_y = (y0 + y1) / 2

            # Append formatted line for YOLO
            yolo_data.append(f"{class_id} {center_x / fix_width} {center_y / fix_height} {w / fix_width} {h / fix_height}\n")

    # Write annotation file if bounding boxes are present
    if yolo_data:
        with open(output_path, 'w') as fout:
            fout.writelines(yolo_data)

# Function to process the JSONL file
def pubtabnet_to_yolo(annotation_file='annotation.jsonl', split='train', yolo_base_dir='yolo_dataset', image_base_dir='images'):
    os.makedirs(os.path.join(yolo_base_dir, 'labels'), exist_ok=True)
    with open(annotation_file, 'r', encoding='utf-8') as file:
        for line in file:
          data = json.loads(line)
          if data['split'] == split:
            pubtabnet_to_yolo_single(data, yolo_base_dir, image_base_dir)

    print(f"Processed all {split} data from {annotation_file}")

# Run the conversion for the desired split (e.g., 'train')
pubtabnet_to_yolo(
    annotation_file=fintabnet_original_dataset_dir + '/annotation.jsonl',
    split='train',
    yolo_base_dir=fintabnet_yolo_format_dataset_dir+ '/labels/train',
    image_base_dir=fintabnet_original_dataset_dir + '/train')
pubtabnet_to_yolo(
    annotation_file=fintabnet_original_dataset_dir + '/annotation.jsonl',
    split='val',
    yolo_base_dir=fintabnet_yolo_format_dataset_dir+ '/labels/val',
    image_base_dir=fintabnet_original_dataset_dir + '/val')
pubtabnet_to_yolo(
    annotation_file=fintabnet_original_dataset_dir + '/annotation.jsonl',
    split='test',
    yolo_base_dir=fintabnet_yolo_format_dataset_dir+ '/labels/test',
    image_base_dir=fintabnet_original_dataset_dir + '/test')

def copy_all_data(source, destination):
    for root, dirs, files in os.walk(source):
        relative_path = os.path.relpath(root, source)
        dest_path = os.path.join(destination, relative_path)
        # print('dest_path=', dest_path)
        # if os.path.exists(dest_path):
        #   shutil.rmtree(dest_path)
        os.makedirs(dest_path, exist_ok=True)

        for file in files:
            src_file = os.path.join(root, file)
            dest_file = os.path.join(dest_path, file)

            shutil.copy2(src_file, dest_file)  # Copy and overwrite if exists
            # print(f"Copied: {src_file} -> {dest_file}")

    print(f"All files and folders have been copied from {source} to {destination}")

copy_all_data(fintabnet_original_dataset_dir + "/test", fintabnet_yolo_format_dataset_dir+"/images/test")
copy_all_data(fintabnet_original_dataset_dir + "/train", fintabnet_yolo_format_dataset_dir+"/images/train")
copy_all_data(fintabnet_original_dataset_dir + "/val", fintabnet_yolo_format_dataset_dir+"/images/val")

import torch
print("CUDA available:", torch.cuda.is_available())
print("Number of GPUs:", torch.cuda.device_count())

# Define the configuration content
yaml_content = """
path: /content/FinTabNetYoloFormatDataset
train: images/train
val: images/val
test: images/test
names: ['table cell header', 'table grid cell']
"""

# Save the configuration to a file
yaml_file_path = "/content/data/yolo8-tsr-config.yaml"
import os

# Ensure the directory exists
os.makedirs(os.path.dirname(yaml_file_path), exist_ok=True)

# Write the content to the file
with open(yaml_file_path, "w") as file:
    file.write(yaml_content)

print(f"YAML file saved to {yaml_file_path}")

# to reset all cache
import torch
torch.cuda.empty_cache()
torch.cuda.reset_max_memory_allocated()
torch.cuda.reset_max_memory_cached()

import os
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"

import torch
torch.cuda.empty_cache()

import os

val_labels_dir = '/content/FinTabNetYoloFormatDataset/labels/val'
val_images_dir = '/content/FinTabNetYoloFormatDataset/images/val'

# List labels and images
val_labels = os.listdir(val_labels_dir)
val_images = os.listdir(val_images_dir)

print("Validation Labels:", val_labels)
print("Validation Images:", val_images)

# Check if each image has a corresponding label file
for image in val_images:
    label_file = os.path.join(val_labels_dir, image.replace('.jpg', '.txt').replace('.png', '.txt'))
    if not os.path.exists(label_file):
        print(f"Missing label for {image}")

import os

# Path to the directory with label files
labels_dir = '/content/FinTabNetYoloFormatDataset/labels/train'

# Iterate over each item in the labels directory
for label_file in os.listdir(labels_dir):
    file_path = os.path.join(labels_dir, label_file)

    # Skip directories
    if os.path.isdir(file_path):
        continue

    # Read all lines from the file, filtering out empty lines
    with open(file_path, 'r') as f:
        lines = [line for line in f if line.strip()]  # Keep only non-empty lines

    # Write back the non-empty lines to the file
    with open(file_path, 'w') as f:
        f.writelines(lines)

print("Empty lines removed from all files in the directory.")

import torch
print(torch.cuda.is_available())
print(torch.cuda.current_device())
print(torch.cuda.get_device_name(0))

from ultralytics import YOLO

# Initialize model (you can specify other models like yolov8m.pt if needed)
model = YOLO('yolov8s.pt')
# Check if the model and all operations are on the correct device
model.to(torch.device("cuda:0"))

CONFIDENCE_THRESHOLD = 0.3

# Train the model
model.train(
    data=yaml_file_path,
    name='yolov8s-tsr',
    imgsz=640,  # Image size
    epochs=50,  # Number of epochs
    lr0=0.0005,  # Initial learning rate
    device="cuda:0",  # Use GPU
    workers=8,  # Number of workers
    batch=16,  # Batch size
    multi_scale=True,  # Enable multi-scale training
    val=True,  # Run validation
    save=True,  # Ensure model checkpoints are saved
    save_period=1,  # Save weights every epoch
    patience=10,  # Early stopping if no improvement
    augment=True,  # Enable data augmentation
    perspective=0.0005,  # Perspective augmentation
    shear=0.001,  # Shear augmentation
    flipud=0.5,  # Vertical flipping
    mosaic=1.0,  # Mosaic augmentation
    mixup=0.2  # Mixup augmentation
)

# !cp -r "runs/detect/yolov8s-tsr/weights/best.pt" "/content/drive/MyDrive/pubtabnet/"

# Load the best checkpoint
# best_model = YOLO('runs/detect/yolov8s-tsr/weights/best.pt')

model.val(
  data=yaml_file_path,
  split='val',
  imgsz=640,  # Fixed size per validation pass
  device="cuda:0",  # Use 'cpu' if GPU is unavailable
  batch=16
)

# Run predictions on the test set
results = model.predict(
    source=fintabnet_yolo_format_dataset_dir+"/images/test",  # Path to your test images
    save=True,              # Save predictions
    conf=CONFIDENCE_THRESHOLD,              # Confidence threshold for predictions
    device="cuda:0",
    imgsz=640              # Image size, same as during training
)

# import matplotlib.pyplot as plt
# import matplotlib.patches as patches
# from PIL import Image

# # Set the minimum confidence threshold
# confidence_threshold = 0.5

# # Loop over each prediction result in the test set
# for result in results[:1]:
#     # Load the image
#     image_path = result.path
#     print('image_path=', image_path)
#     image = Image.open(image_path)

#     # Create a plot with the image
#     fig, ax = plt.subplots(1)
#     ax.imshow(image)

#     # Extract bounding boxes, confidences, and class IDs
#     boxes = result.boxes.xyxy  # Bounding box in [x_min, y_min, x_max, y_max] format
#     confidences = result.boxes.conf  # Confidence scores
#     class_ids = result.boxes.cls  # Class IDs

#     # Loop through each detected box and plot it if it meets the confidence threshold
#     for i, box in enumerate(boxes):
#         if confidences[i] >= confidence_threshold:
#             x_min, y_min, x_max, y_max = box.tolist()
#             class_id = int(class_ids[i])  # Convert class_id to an integer

#             # Create a Rectangle patch
#             rect = patches.Rectangle(
#                 (x_min, y_min), x_max - x_min, y_max - y_min,
#                 linewidth=0.5, edgecolor='r', facecolor='none'
#             )
#             ax.add_patch(rect)

#             # Add text label for class_id
#             ax.text(
#                 x_min, y_min - 5, f"Class: {class_id}",
#                 color='white', fontsize=8, backgroundcolor='red'
#             )

#     # Display the plot with bounding boxes and class labels
#     plt.axis('off')
#     plt.show()

import matplotlib.pyplot as plt
import matplotlib.patches as patches
from PIL import Image

# Set the minimum confidence threshold
confidence_threshold = CONFIDENCE_THRESHOLD

# Loop over the first three prediction results in the test set
for index, result in enumerate(results[:3], start=1):
    # Load the image
    image_path = result.path
    image = Image.open(image_path)

    # Create a figure with two subplots: left (grids only) and right (grids + labels)
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 12))  # Two side-by-side subplots

    # Adjust spacing to minimize space above plots
    fig.subplots_adjust(top=0.85)  # Reduce the top margin

    # Set the overall title
    fig.suptitle(
        f"Index: {index} | Image path: {image_path}\n"
        "Left: Grid Detections Only | Right: Grid Detections with Labels",
        fontsize=16,
        y=0.92  # Adjust title position closer to the plots
    )

    # Left plot: Show grid detections only
    ax1.imshow(image)
    ax1.set_title("Grid Detections Only", fontsize=14)
    ax1.axis('off')

    # Right plot: Show grid detections with labels
    ax2.imshow(image)
    ax2.set_title("Grid Detections with Labels", fontsize=14)
    ax2.axis('off')

    # Extract bounding boxes, confidences, and class IDs
    boxes = result.boxes.xyxy  # Bounding box in [x_min, y_min, x_max, y_max] format
    confidences = result.boxes.conf  # Confidence scores
    class_ids = result.boxes.cls  # Class IDs

    # Loop through each detected box and plot it if it meets the confidence threshold
    for i, box in enumerate(boxes):
        if confidences[i] >= confidence_threshold:
            x_min, y_min, x_max, y_max = box.tolist()
            class_id = int(class_ids[i])  # Convert class_id to an integer

            # Create a Rectangle patch for the left plot (grid only)
            rect1 = patches.Rectangle(
                (x_min, y_min), x_max - x_min, y_max - y_min,
                linewidth=2, edgecolor='r', facecolor='none'  # Increase line width
            )
            ax1.add_patch(rect1)

            # Create a Rectangle patch for the right plot (grid + labels)
            rect2 = patches.Rectangle(
                (x_min, y_min), x_max - x_min, y_max - y_min,
                linewidth=2, edgecolor='r', facecolor='none'  # Increase line width
            )
            ax2.add_patch(rect2)

            # Add labels to the right plot
            ax2.text(
                x_min, y_min - 10,  # Place text above the box
                f"Class: {class_id} ({confidences[i]:.2f})",
                color='white', fontsize=10,  # Increase font size for visibility
                bbox=dict(facecolor='red', alpha=0.6, edgecolor='none')  # Semi-transparent label
            )

    # Show the side-by-side plots
    plt.tight_layout()  # Adjust layout to avoid overlapping
    plt.show()

# import matplotlib.pyplot as plt
# import matplotlib.patches as patches
# from PIL import Image

# # Set the minimum confidence threshold
# confidence_threshold = 0.5

# # Loop over each prediction result in the test set
# for result in results[:1]:
#     # Load the image
#     image_path = result.path
#     print('image_path=', image_path)
#     image = Image.open(image_path)

#     # Create a plot with the image
#     fig, ax = plt.subplots(1)
#     ax.imshow(image)

#     # Extract bounding boxes, confidences, and class IDs
#     boxes = result.boxes.xyxy  # Bounding box in [x_min, y_min, x_max, y_max] format
#     confidences = result.boxes.conf  # Confidence scores
#     class_ids = result.boxes.cls  # Class IDs

#     # Loop through each detected box and plot it if it meets the confidence threshold
#     for i, box in enumerate(boxes):
#         if confidences[i] >= confidence_threshold:
#             x_min, y_min, x_max, y_max = box.tolist()

#             # Create a Rectangle patch
#             rect = patches.Rectangle(
#                 (x_min, y_min), x_max - x_min, y_max - y_min,
#                 linewidth=0.5, edgecolor='r', facecolor='none'
#             )
#             ax.add_patch(rect)

#     # Display the plot with bounding boxes
#     plt.axis('off')
#     plt.show()

# !apt-get update
# !apt-get install -y tesseract-ocr

# import pytesseract
# from PIL import Image
# import pandas as pd
# from lxml import html

# # Set the minimum confidence threshold
# confidence_threshold = 0.5

# # Helper function to check if two boxes overlap
# def boxes_overlap(box1, box2):
#     x_min1, y_min1, x_max1, y_max1 = box1
#     x_min2, y_min2, x_max2, y_max2 = box2
#     return not (x_max1 <= x_min2 or x_min1 >= x_max2 or y_max1 <= y_min2 or y_min1 >= y_max2)

# # Filter overlapping boxes based on confidence score
# def filter_overlapping_boxes(boxes, confidences):
#     filtered_boxes = []
#     for i, box1 in enumerate(boxes):
#         keep = True
#         for j, box2 in enumerate(boxes):
#             if i != j and boxes_overlap(box1, box2):
#                 # Keep the box with the higher confidence score
#                 if confidences[i] < confidences[j]:
#                     keep = False
#                     break
#         if keep:
#             filtered_boxes.append(i)
#     return filtered_boxes

# # Initialize lists to store header and body cell data
# header_cells = []
# body_cells = []

# # Loop over each prediction result in the test set
# for result in results[:1]:  # Adjust as needed
#     # Load the image
#     image_path = result.path
#     image = Image.open(image_path)
#     print('image_path=', image_path)

#     # Extract bounding boxes, confidences, and class IDs
#     boxes = result.boxes.xyxy  # Bounding box in [x_min, y_min, x_max, y_max] format
#     confidences = result.boxes.conf  # Confidence scores
#     class_ids = result.boxes.cls  # Class IDs

#     # Filter boxes to remove overlapping ones
#     filtered_indices = filter_overlapping_boxes(boxes.tolist(), confidences.tolist())

#     # Loop through each filtered box and process if it meets the confidence threshold
#     for i in filtered_indices:
#         if confidences[i] >= confidence_threshold:
#             x_min, y_min, x_max, y_max = boxes[i].tolist()
#             class_id = int(class_ids[i])

#             # Crop the content within the bounding box and perform OCR
#             cropped_image = image.crop((x_min, y_min, x_max, y_max))
#             extracted_text = pytesseract.image_to_string(cropped_image, config='--psm 6').strip()

#             # Append text to header or body based on class_id
#             if class_id == 0:
#                 header_cells.append(extracted_text)
#             else:
#                 body_cells.append(extracted_text)

# # Generate HTML for the table content with optional <thead> and <tbody>
# def html_table_template(header_content, body_content):
#     # Conditionally include <thead> if there are header cells
#     thead_html = f"<thead><tr>{header_content}</tr></thead>" if header_content else ""
#     return f"""<html>
#         <head><meta charset="UTF-8">
#         <style>
#         table, th, td {{
#             border: 1px solid black;
#             font-size: 10px;
#         }}
#         </style></head>
#         <body>
#         <table frame="hsides" rules="groups" width="100%">
#             {thead_html}
#             <tbody>{body_content}</tbody>
#         </table></body></html>"""

# # Convert header cells to HTML <th> tags if they exist
# header_html = "".join(f"<td>{cell}</td>" for cell in header_cells)

# # Convert body cells to HTML <td> tags within rows
# body_rows_html = ""
# for cell_text in body_cells:
#     body_rows_html += f"<tr><td>{cell_text}</td></tr>"

# # Generate the final HTML for the predicted table
# predicted_html = html_table_template(header_html, body_rows_html)

# # Print or save the generated HTML
# print(predicted_html)

# # Loop over each prediction result in the test set
# for result in results:
#     print(f"Image: {result.path}")  # Image path

#     # Extract bounding boxes, confidences, and class IDs
#     boxes = result.boxes.xyxy  # Bounding box in [x_min, y_min, x_max, y_max] format
#     confidences = result.boxes.conf  # Confidence scores
#     classes = result.boxes.cls  # Class IDs

#     for i, box in enumerate(boxes):
#         print(f"Bounding Box {i + 1}:")
#         print(f" - Coordinates: {box}")
#         print(f" - Confidence: {confidences[i].item()}")
#         print(f" - Class ID: {classes[i].item()}")

# import json

# # List to hold results
# prediction_results = []

# # Populate the list with bounding box data
# for result in results:
#     image_data = {
#         "image": result.path,
#         "boxes": []
#     }

#     for i, box in enumerate(result.boxes.xyxy):
#         box_data = {
#             "coordinates": box.tolist(),
#             "confidence": result.boxes.conf[i].item(),
#             "class_id": int(result.boxes.cls[i].item())
#         }
#         image_data["boxes"].append(box_data)

#     prediction_results.append(image_data)

# # Save to JSON
# json_file_path = "/content/bbox_predictions.json"
# with open(json_file_path, "w") as f:
#     json.dump(prediction_results, f)

# print(f"Predictions saved to {json_file_path}")

import apted
import distance
from collections import deque
from lxml import etree, html
from tqdm import tqdm
from concurrent.futures import ProcessPoolExecutor, as_completed
from typing import Tuple

class CustomConfig(apted.Config):
    @staticmethod
    def maximum(*sequences):
        """Get maximum possible value."""
        return max(map(len, sequences))

    def normalized_distance(self, *sequences):
        """Get distance from 0 to 1."""
        return float(distance.levenshtein(*sequences)) / self.maximum(*sequences)

    def rename(self, node1, node2):
        """Compares attributes of trees"""
        if (
            (node1.tag != node2.tag)
            or (node1.colspan != node2.colspan)
            or (node1.rowspan != node2.rowspan)
        ):
            return 1.0
        if node1.tag == "td":
            if node1.content or node2.content:
                return self.normalized_distance(node1.content, node2.content)
        return 0.0

class TableTree(apted.helpers.Tree):
    def __init__(self, tag, colspan=None, rowspan=None, content=None, *children):
        self.tag = tag
        self.colspan = colspan
        self.rowspan = rowspan
        self.content = content
        self.children = list(children)

    def bracket(self):
        """Show tree using brackets notation."""
        if self.tag == "td":
            result = '"tag": %s, "colspan": %d, "rowspan": %d, "text": %s' % (
                self.tag,
                self.colspan,
                self.rowspan,
                self.content,
            )
        else:
            result = '"tag": %s' % self.tag
        for child in self.children:
            result += child.bracket()
        return "{{{}}}".format(result)

class TEDS(object):
    """Tree Edit Distance basead Similarity"""

    def __init__(self, structure_only=False, n_jobs=1, ignore_nodes=None):
        assert isinstance(n_jobs, int) and (
            n_jobs >= 1
        ), "n_jobs must be an integer greather than 1"
        self.structure_only = structure_only
        self.n_jobs = n_jobs
        self.ignore_nodes = ignore_nodes
        self.__tokens__ = []

    def tokenize(self, node):
        """Tokenizes table cells"""
        self.__tokens__.append("<%s>" % node.tag)
        if node.text is not None:
            self.__tokens__ += list(node.text)
        for n in node.getchildren():
            self.tokenize(n)
        if node.tag != "unk":
            self.__tokens__.append("</%s>" % node.tag)
        if node.tag != "td" and node.tail is not None:
            self.__tokens__ += list(node.tail)

    def load_html_tree(self, node, parent=None):
        """Converts HTML tree to the format required by apted"""
        global __tokens__
        if node.tag == "td":
            if self.structure_only:
                cell = []
            else:
                self.__tokens__ = []
                self.tokenize(node)
                cell = self.__tokens__[1:-1].copy()
            new_node = TableTree(
                node.tag,
                int(node.attrib.get("colspan", "1")),
                int(node.attrib.get("rowspan", "1")),
                cell,
                *deque(),
            )
        else:
            new_node = TableTree(node.tag, None, None, None, *deque())
        if parent is not None:
            parent.children.append(new_node)
        if node.tag != "td":
            for n in node.getchildren():
                self.load_html_tree(n, new_node)
        if parent is None:
            return new_node

    def evaluate(self, pred, true):
        """Computes TEDS score between the prediction and the ground truth of a
        given sample
        """
        if (not pred) or (not true):
            return 0.0
        parser = html.HTMLParser(remove_comments=True, encoding="utf-8")
        pred = html.fromstring(pred, parser=parser)
        true = html.fromstring(true, parser=parser)
        if pred.xpath("body/table") and true.xpath("body/table"):
            pred = pred.xpath("body/table")[0]
            true = true.xpath("body/table")[0]
            if self.ignore_nodes:
                etree.strip_tags(pred, *self.ignore_nodes)
                etree.strip_tags(true, *self.ignore_nodes)
            n_nodes_pred = len(pred.xpath(".//*"))
            n_nodes_true = len(true.xpath(".//*"))
            n_nodes = max(n_nodes_pred, n_nodes_true)
            tree_pred = self.load_html_tree(pred)
            tree_true = self.load_html_tree(true)
            distance = apted.APTED(
                tree_pred, tree_true, CustomConfig()
            ).compute_edit_distance()
            return 1.0 - (float(distance) / n_nodes)
        else:
            return 0.0

    def batch_evaluate(self, results_json):
        """Computes TEDS score between the prediction and the ground truth of
        a batch of samples
        @params pred_json: {'FILENAME': 'HTML CODE', ...}
        @params true_json: {'FILENAME': {'html': 'HTML CODE'}, ...}
        @output: {'FILENAME': 'TEDS SCORE', ...}
        """
        samples = results_json.keys()
        print(f"Total samples: {len(samples)}")
        if self.n_jobs == 1:
            scores = [
                self.evaluate(
                    results_json[filename]["pred"],
                    results_json[filename]["gt"],
                )
                for filename in tqdm(samples)
            ]
        else:
            inputs = [
                {
                    "pred": results_json[filename]["pred"],
                    "true": results_json[filename]["gt"],
                }
                for filename in samples
            ]
            scores = parallel_process(
                inputs, self.evaluate, use_kwargs=True, n_jobs=self.n_jobs, front_num=1
            )
        output = dict()
        for i, j in zip(samples, scores):
            if "span" in results_json[i]["gt"]:
                output[i] = dict(scores=j, type="complex")
            else:
                output[i] = dict(scores=j, type="simple")
        # scores = dict(zip(samples, scores))
        return output


def parallel_process(array, function, n_jobs=16, use_kwargs=False, front_num=0):
    """
    A parallel version of the map function with a progress bar.

    Args:
        array (array-like): An array to iterate over.
        function (function): A python function to apply to the elements of array
        n_jobs (int, default=16): The number of cores to use
        use_kwargs (boolean, default=False): Whether to consider the elements of array as dictionaries of
            keyword arguments to function
        front_num (int, default=3): The number of iterations to run serially before kicking off the parallel job.
            Useful for catching bugs
    Returns:
        [function(array[0]), function(array[1]), ...]
    """
    # We run the first few iterations serially to catch bugs
    if front_num > 0:
        front = [
            function(**a) if use_kwargs else function(a) for a in array[:front_num]
        ]
    else:
        front = []
    # If we set n_jobs to 1, just run a list comprehension. This is useful for benchmarking and debugging.
    if n_jobs == 1:
        return front + [
            function(**a) if use_kwargs else function(a)
            for a in tqdm(array[front_num:])
        ]
    # Assemble the workers
    with ProcessPoolExecutor(max_workers=n_jobs) as pool:
        # Pass the elements of array into function
        if use_kwargs:
            futures = [pool.submit(function, **a) for a in array[front_num:]]
        else:
            futures = [pool.submit(function, a) for a in array[front_num:]]
        kwargs = {
            "total": len(futures),
            "unit": "it",
            "unit_scale": True,
            "leave": True,
        }
        # Print out the progress as tasks complete
        for f in tqdm(as_completed(futures), **kwargs):
            pass
    out = []
    # Get the results from the futures.
    for i, future in tqdm(enumerate(futures)):
        try:
            out.append(future.result())
        except Exception as e:
            out.append(e)
    return front + out

CELL_SPECIAL = ["<b>", "</b>", "<i>", "</i>", "<sup>", "</sup>", "<sub>", "</sub>"]

# Load groundtruth annotation
annotation_path = f"{fintabnet_original_dataset_dir}/annotation.jsonl"
with jsonlines.open(annotation_path) as f:
    for obj in f:
      # image_path= /content/FinTabNetYoloFormatDataset/images/test/PMC1064888_001_02.png
        # if obj["filename"] == image_name:
        if obj["filename"] == "PMC1064888_001_02.png":
            anno_html_raw = obj["html"]["structure"]["tokens"]
            anno_cell_raw = ["".join(cell["tokens"]) for cell in obj["html"]["cells"] if cell["tokens"]]
            break
        # anno_html_raw = obj["html"]["structure"]["tokens"]
        # anno_cell_raw = ["".join(cell["tokens"]) for cell in obj["html"]["cells"] if cell["tokens"]]

anno_html = []
idx = 0
while idx < len(anno_html_raw):
    if "[" in anno_html_raw[idx]:
        assert idx + 1 < len(anno_html_raw)
        assert anno_html_raw[idx + 1] == "]</td>"
        anno_html.append(anno_html_raw[idx] + "]</td>")
        idx = idx + 2
    else:
        anno_html.append(anno_html_raw[idx])
        idx = idx + 1

anno_cell = []
for txt in anno_cell_raw:
    for black in CELL_SPECIAL:
        txt = txt.replace(black, "")
    anno_cell.append(txt)

anno_code = "".join(build_table_from_html_and_cell(anno_html, anno_cell))
print('anno_code=', anno_code)

import matplotlib.pyplot as plt
import matplotlib.patches as patches
from PIL import Image
from lxml import html

# Set the minimum confidence threshold
confidence_threshold = 0.5
row_threshold = 10  # Maximum difference in y_min to consider cells as part of the same row

# Helper function to check if two boxes overlap
def boxes_overlap(box1, box2):
    x_min1, y_min1, x_max1, y_max1 = box1
    x_min2, y_min2, x_max2, y_max2 = box2
    return not (x_max1 <= x_min2 or x_min1 >= x_max2 or y_max1 <= y_min2 or y_min1 >= y_max2)

# Filter overlapping boxes based on confidence score
def filter_overlapping_boxes(boxes, confidences):
    filtered_boxes = []
    for i, box1 in enumerate(boxes):
        keep = True
        for j, box2 in enumerate(boxes):
            if i != j and boxes_overlap(box1, box2):
                # Keep the box with the higher confidence score
                if confidences[i] < confidences[j]:
                    keep = False
                    break
        if keep:
            filtered_boxes.append(i)
    return filtered_boxes

# Initialize lists to store header and body cell data
header_cells = []
body_cells = []

# Loop over each prediction result in the test set
for result in results[:10]:  # Adjust as needed
    # Load the image
    image_path = result.path
    image = Image.open(image_path)
    print('image_path=', image_path)

    # Extract bounding boxes, confidences, and class IDs
    boxes = result.boxes.xyxy  # Bounding box in [x_min, y_min, x_max, y_max] format
    confidences = result.boxes.conf  # Confidence scores
    class_ids = result.boxes.cls  # Class IDs

    # Filter boxes to remove overlapping ones
    filtered_indices = filter_overlapping_boxes(boxes.tolist(), confidences.tolist())

    # Collect filtered cells with position information for row detection
    detected_cells = []
    for i in filtered_indices:
        if confidences[i] >= confidence_threshold:
            x_min, y_min, x_max, y_max = boxes[i].tolist()
            class_id = int(class_ids[i])

            # Append cell information including y_min for row grouping
            detected_cells.append({
                "class_id": class_id,
                "y_min": y_min,
                "x_min": x_min,
                "x_max": x_max,
                "y_max": y_max
            })

    # Sort cells by y_min, then by x_min to group into rows and columns
    detected_cells.sort(key=lambda cell: (cell["y_min"], cell["x_min"]))

    # Group cells into rows based on y_min similarity
    rows = []
    current_row = []
    current_y = detected_cells[0]["y_min"] if detected_cells else None

    for cell in detected_cells:
        if abs(cell["y_min"] - current_y) > row_threshold:  # New row if y_min differs significantly
            rows.append(current_row)
            current_row = []
            current_y = cell["y_min"]
        current_row.append(cell)
    if current_row:  # Add the last row if it's non-empty
        rows.append(current_row)

    # Visualization of the filtered boxes
    fig, ax = plt.subplots(1, figsize=(12, 12))
    ax.imshow(image)
    ax.set_title("Filtered Table Structure with Bounding Boxes", fontsize=14)

    # Draw the filtered bounding boxes
    for cell in detected_cells:
        x_min, y_min, x_max, y_max = cell["x_min"], cell["y_min"], cell["x_max"], cell["y_max"]
        class_id = cell["class_id"]

        # Create a Rectangle patch
        rect = patches.Rectangle(
            (x_min, y_min), x_max - x_min, y_max - y_min,
            linewidth=2, edgecolor='r' if class_id == 0 else 'b', facecolor='none'
        )
        ax.add_patch(rect)

        # Add text label for class_id
        ax.text(
            x_min, y_min - 5, f"Class: {class_id}",
            color='white', fontsize=8, bbox=dict(facecolor='red' if class_id == 0 else 'blue', alpha=0.6)
        )

    plt.axis('off')
    plt.show()


import matplotlib.pyplot as plt
import matplotlib.patches as patches
from PIL import Image
import jsonlines

# Set constants
CONFIDENCE_THRESHOLD = 0.5
ROW_THRESHOLD = 10  # Maximum y_min difference to group cells into the same row
CELL_SPECIAL = ["<b>", "</b>", "<i>", "</i>", "<sup>", "</sup>", "<sub>", "</sub>"]

def build_table_from_html_and_cell(structure, content):
    """Build table from HTML structure and cell content."""
    assert structure is not None
    html_code = []
    if content is None:
        content = ["placeholder"] * len(structure)
    for tag in structure:
        if tag in ("<td>[]</td>", ">[]</td>"):
            if len(content) == 0:
                continue
            cell = content.pop(0)
            html_code.append(tag.replace("[]", cell))
        else:
            html_code.append(tag)
    return html_code

# Helper function to check if two boxes overlap
def boxes_overlap(box1, box2):
    x_min1, y_min1, x_max1, y_max1 = box1
    x_min2, y_min2, x_max2, y_max2 = box2
    return not (x_max1 <= x_min2 or x_min1 >= x_max2 or y_max1 <= y_min2 or y_min1 >= y_max2)

def filter_overlapping_boxes(boxes, confidences):
    """Filter overlapping boxes based on confidence scores."""
    filtered_boxes = []
    for i, box1 in enumerate(boxes):
        keep = True
        for j, box2 in enumerate(boxes):
            if i != j and boxes_overlap(box1, box2):
                if confidences[i] < confidences[j]:  # Keep higher confidence box
                    keep = False
                    break
        if keep:
            filtered_boxes.append(i)
    return filtered_boxes

def predicted_html_table_template(header_content, body_content):
    """Generate HTML template for predicted table."""
    thead_html = f"<thead>{header_content}</thead>" if header_content else ""
    return f"""<html>
        <head><meta charset="UTF-8">
        <style>
        table, th, td {{
            border: 1px solid black;
            font-size: 10px;
        }}
        </style></head>
        <body>
        <table frame="hsides" rules="groups" width="100%">
            {thead_html}
            <tbody>{body_content}</tbody>
        </table></body></html>"""

def anno_code_html_table_template(table):
    """Generate HTML for groundtruth annotations."""
    return f"""<html>
        <head><meta charset="UTF-8">
        <style>
        table, th, td {{
            border: 1px solid black;
            font-size: 10px;
        }}
        </style></head>
        <body>
        <table frame="hsides" rules="groups" width="100%">
            {table}
        </table></body></html>"""

def calculate_spans(cell, rows, current_row):
    """Calculate rowspan and colspan for a cell."""
    rowspan, colspan = 1, 1
    for next_row in rows:
        for next_cell in next_row:
            if (
                cell["x_min"] == next_cell["x_min"]
                and cell["x_max"] == next_cell["x_max"]
                and next_cell["y_min"] > cell["y_min"]
                and next_cell["y_min"] < cell["y_max"]
            ):
                rowspan += 1
    for next_cell in current_row:
        if (
            cell["y_min"] == next_cell["y_min"]
            and cell["y_max"] == next_cell["y_max"]
            and next_cell["x_min"] > cell["x_min"]
            and next_cell["x_min"] < cell["x_max"]
        ):
            colspan += 1
    return rowspan, colspan

# Main processing loop
average_TEDS = 0
experiment_results = results

# Additional helper function to resolve overlapping cells within a row
def resolve_row_overlaps(row):
    """
    Resolve overlapping cells within a single row based on x_min.
    Keeps the cell with the higher confidence or larger area in case of ties.
    """
    resolved_row = []
    row.sort(key=lambda cell: cell["x_min"])  # Sort by x_min

    for cell in row:
        if not resolved_row:
            resolved_row.append(cell)
        else:
            last_cell = resolved_row[-1]
            if cell["x_min"] < last_cell["x_max"]:  # Overlap detected
                # Keep the cell with higher confidence
                if cell.get("confidence", 0) > last_cell.get("confidence", 0):
                    resolved_row[-1] = cell
            else:
                resolved_row.append(cell)

    return resolved_row

for result in experiment_results:
    # Load image and extract predictions
    image_path = result.path
    image = Image.open(image_path)
    boxes = result.boxes.xyxy.tolist()
    confidences = result.boxes.conf.tolist()
    class_ids = result.boxes.cls.tolist()

    # Filter overlapping boxes
    filtered_indices = filter_overlapping_boxes(boxes, confidences)
    detected_cells = [
        {
            "class_id": int(class_ids[i]),
            "y_min": boxes[i][1],
            "x_min": boxes[i][0],
            "x_max": boxes[i][2],
            "y_max": boxes[i][3],
        }
        for i in filtered_indices if confidences[i] >= CONFIDENCE_THRESHOLD
    ]

    # Sort and group cells into rows
    detected_cells.sort(key=lambda cell: (cell["y_min"], cell["x_min"]))
    rows, current_row, current_y = [], [], detected_cells[0]["y_min"] if detected_cells else None

    for cell in detected_cells:
        if abs(cell["y_min"] - current_y) > ROW_THRESHOLD:
            current_row = resolve_row_overlaps(current_row)
            rows.append(current_row)
            current_row = []
            current_y = cell["y_min"]
        current_row.append(cell)
    if len(current_row) > 0:
        current_row = resolve_row_overlaps(current_row)
        # print('current_row=', current_row)
        rows.append(current_row)

    # Visualization
    fig, ax = plt.subplots(1, figsize=(12, 12))
    ax.imshow(image)
    ax.set_title("Table Detection with Bounding Boxes and Spans", fontsize=14)

    # Build HTML content with spans
    header_html, body_rows_html = "", ""
    processed_cells = set()

    # Find the row with the maximum number of cells
    max_cells_row = max(rows, key=len)
    max_columns = len(max_cells_row)
    max_cell_positions = [cell["x_max"] for cell in max_cells_row]  # Get x_min positions of maximum cell row

    # Sort max_cell_positions to ensure alignment
    max_cell_positions.sort()
    # print('max_cell_positions=', max_cell_positions)

    for idx, row in enumerate(rows):
      row_html = ""  # Initialize the HTML for the current row
      is_header_row = idx == 0 or any(cell["class_id"] == 0 for cell in row)  # Treat the first row as a header

      # Keep track of the current column index to add padding if necessary
      # Iterate through max_cell_positions to fill missing cells
      max_position_index = 0  # Keep track of the current position in the max_cell_positions
      total_filled_cell = 0
      total_cell = 0

      # Sort the row by x_min to ensure cells are processed in the correct horizontal order
      row.sort(key=lambda cell: cell["x_min"])
      # print('row=', row)

      for cell in row:
          if (cell["x_min"], cell["y_min"]) in processed_cells:
              continue  # Skip already processed spanning cells

          total_unfilled_cells = 0
           # Fill gaps with missing cells before processing the current cell
          while max_position_index < len(max_cell_positions) and cell["x_min"] > max_cell_positions[max_position_index]:
              max_position_index += 1
              total_unfilled_cells += 1

          total_cell += 1
          if (total_unfilled_cells - total_filled_cell) > 1:
            # Add missing cell with span
            # print('Planning:' , f'<td colspan="{int(total_unfilled_cells)}"></td>')
            row_html += f'<td colspan="{int(total_unfilled_cells)}"></td>'
            total_cell += (total_unfilled_cells - total_filled_cell)
          elif (total_unfilled_cells - total_filled_cell) == 1:
            row_html += '<td></td>'
            # print('Planning:' , '<td></td>')
            total_cell += (total_unfilled_cells - total_filled_cell)
          total_filled_cell += 1

          # Calculate spans for the cell
          rowspan, colspan = calculate_spans(cell, rows, row)
          span_attributes = (
              f' rowspan="{rowspan}"' if rowspan > 1 else ""
          ) + (f' colspan="{colspan}"' if colspan > 1 else "")


          # Add the cell with calculated spans to the row HTML
          row_html += f'<td{span_attributes}></td>'

          # Mark this cell and its spans as processed
          for r in range(rowspan):
              for c in range(colspan):
                  processed_cells.add((cell["x_min"] + c, cell["y_min"] + r))


          # Visualization for spans
          rect = patches.Rectangle(
              (cell["x_min"], cell["y_min"]),
              cell["x_max"] - cell["x_min"],
              cell["y_max"] - cell["y_min"],
              linewidth=2,
              edgecolor="r" if is_header_row else "b",  # Red for headers, blue for body
              facecolor="none",
          )
          ax.add_patch(rect)
          max_position_index += 1  # Move to the next max_cell_position

      if total_cell < max_columns:
        # print('max_columns=', max_columns, ', total_cell=', total_cell)
        # Check if there is already a last <td></td> to replace
        if row_html.endswith('<td></td>'):
            # Remove the last <td></td> and replace it with a colspan
            row_html = row_html[:-9] + f'<td colspan="{int(max_columns - total_cell + 1)}"></td>'
        else:
            # Add a new <td> with the calculated colspan if no <td></td> exists
            row_html += f'<td colspan="{int(max_columns - total_cell)}"></td>'
      # print('row_html=', row_html)
      if is_header_row:
          header_html += f"<tr>{row_html}</tr>"
      else:
          body_rows_html += f"<tr>{row_html}</tr>"


    plt.axis("off")
    plt.show()

    predicted_html = predicted_html_table_template(header_html, body_rows_html)

    # Load groundtruth annotations
    annotation_path = f"{fintabnet_original_dataset_dir}/annotation.jsonl"
    with jsonlines.open(annotation_path) as f:
        for obj in f:
            if obj["filename"] == image_path.split("/")[-1]:
                anno_html_raw = obj["html"]["structure"]["tokens"]
                anno_cell_raw = ["".join(cell["tokens"]) for cell in obj["html"]["cells"] if cell["tokens"]]
                break

     # Process groundtruth annotations
    anno_html = []
    idx = 0
    while idx < len(anno_html_raw):
        if "[" in anno_html_raw[idx]:
            assert idx + 1 < len(anno_html_raw) and anno_html_raw[idx + 1] == "]</td>"
            anno_html.append(anno_html_raw[idx] + "]</td>")
            idx += 2
        else:
            anno_html.append(anno_html_raw[idx])
            idx += 1

    anno_cell = []
    for txt in anno_cell_raw:
        for special_char in CELL_SPECIAL:
            txt = txt.replace(special_char, "")
        anno_cell.append(txt)

    anno_code = "".join(build_table_from_html_and_cell(anno_html, anno_cell))

    # Evaluate table structure
    teds = TEDS(structure_only=True)
    # predicted_html = """<html>
    #     <head><meta charset="UTF-8">
    #     <style>
    #     table, th, td {
    #         border: 1px solid black;
    #         font-size: 10px;
    #     }
    #     </style></head>
    #     <body>
    #     <table frame="hsides" rules="groups" width="100%">
    #         <thead><tr><td></td><td></td><td colspan="6"></td></tr></thead>
    #         <tbody><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr></tbody>
    #     </table></body></html>"""
    score = teds.evaluate(predicted_html, anno_code_html_table_template(anno_code))

    print(f"S-TEDS Score: {score}, Image Path: {image_path}, Predicted HTML: {predicted_html}")
    average_TEDS += score

    print("Average S-TEDS Score:", average_TEDS / len(experiment_results))

    print("Average S-TEDS Score:", average_TEDS / len(experiment_results))